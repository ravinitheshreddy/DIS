{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing\n",
    "\n",
    "\n",
    "In this exercise, we will run latent semantic indexing on a term-document matrix using python numpy library.\n",
    "\n",
    "Suppose we are given the following term-document matrix containing eleven terms and four documents $d_1$ , $d_2$ , $d_3$ and $d_4$:\n",
    "\n",
    "$\n",
    "M =\n",
    "  \\begin{bmatrix}\n",
    "    d_1 & d_2 & d_3 & d_4 \\\\ \n",
    "\t1 & 1 & 1 & 1  \\\\\n",
    "\t0 & 1 & 1 & 1 \\\\\n",
    "\t1 & 0 & 0 & 0 \\\\\n",
    "\t0 & 1 & 0 & 0 \\\\\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    1 & 0 & 1 & 2 \\\\\n",
    "    1 & 1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 & 0 \\\\\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    0 & 2 & 1 & 1 \\\\\n",
    "    0 & 1 & 1 & 0 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "###  Question 1.a\n",
    "\n",
    "Compute the singular value decomposition of the term-document matrix M. Print the values of the output matrices $K$, $S$ and $D^t$.\n",
    "\n",
    "\n",
    "<b>Hint:</b> Use the function numpy.linalg.svd. More details of this function can be found here at this link:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "\n",
    "Here's sample code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Python matrix operations library\n",
    "import numpy as np\n",
    "\n",
    "#set M matrix using the given values.\n",
    "M = [[1,1,1,1], \n",
    "     [0,1,1,1],\n",
    "     [1,0,0,0],\n",
    "     [0,1,0,0],\n",
    "     [1,0,0,0],\n",
    "     [1,0,1,2],\n",
    "     [1,1,1,1],\n",
    "     [1,1,1,0],\n",
    "     [1,0,0,0],\n",
    "     [0,2,1,1],\n",
    "     [0,1,1,0]]\n",
    "\n",
    "\n",
    "M = np.array(M)\n",
    "\n",
    "# compute SVD\n",
    "... = np.linalg.svd(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Question 1.b\n",
    "\n",
    "Are the values of $S$ sorted? Perform latent semantic indexing by selecting the first two largest singular values of the matrix $S$.\n",
    "\n",
    "<b>Hint:</b> See the lecture slides on latent semantic indexing for more details. A sub-matrix of a numpy matrix can be computed using indexing operations (see https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_sel = K[...]\n",
    "S_sel = ...\n",
    "Dt_sel = Dt[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 1.c\n",
    "\n",
    "Given the query $q$:\n",
    "\n",
    "$\n",
    "q =\n",
    "  \\begin{bmatrix}\n",
    "\t0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "Map query $q$ into the new document space $D$. The new query is referred to as $q^*$. \n",
    "\n",
    "<b>Hint:</b> Use the formulation for mapping queries provided in the lecture slides. You can also use np.linalg.inv function for computing the inverse of a matrix.\n",
    "\n",
    "###  Question 1.d\n",
    "\n",
    "Arrange the documents based on the cosine similarity measure between $q^*$ and the new documents in the space $D$.\n",
    "\n",
    "<b>Hint:</b> Use the cosine similarity function from the previous exercise on vector space retrieval.\n",
    "\n",
    "###  Question 1.e\n",
    "\n",
    "Does the order of documents change if document $d_3$ is dropped? If yes, why? \n",
    "If no, how should $d_3$ be modified to change the document ordering?\n",
    "\n",
    "\n",
    "### Question 1.f [Optional]\n",
    "\n",
    "Run latent semantic indexing for the document collection presented in the previous exercise (presented here as well):\n",
    "\n",
    "  DocID | Document Text\n",
    "  ------|------------------\n",
    "  1     | How to Bake Breads Without Baking Recipes\n",
    "  2     | Smith Pies: Best Pies in London\n",
    "  3     | Numerical Recipes: The Art of Scientific Computing\n",
    "  4     | Breads, Pastries, Pies, and Cakes: Quantity Baking Recipes\n",
    "  5     | Pastry: A Book of Best French Pastry Recipes\n",
    "\n",
    "Now, for the query $Q=$''<i>baking</i>'', find the top ranked documents according to LSI (use three singular values). \n",
    "\n",
    "<b>Hint:</b> Use the code for computing document_vectors from the last exercise. However note that document_vectors represent document-term matrix whereas LSI uses term-document matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
