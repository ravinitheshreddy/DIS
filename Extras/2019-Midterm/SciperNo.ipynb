{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Rename-your-notebook\" data-toc-modified-id=\"Rename-your-notebook-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Rename your notebook</a></span></li><li><span><a href=\"#Build-the-vocabulary-by-selecting-top-k-frequent-words\" data-toc-modified-id=\"Build-the-vocabulary-by-selecting-top-k-frequent-words-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Build the vocabulary by selecting top-k frequent words</a></span></li><li><span><a href=\"#Construct-the-term-document-matrix\" data-toc-modified-id=\"Construct-the-term-document-matrix-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Construct the term document matrix</a></span></li><li><span><a href=\"#Perform-LSI-by-selecting-the-first-100-largest-singular-values-of-the-term-document-matrix\" data-toc-modified-id=\"Perform-LSI-by-selecting-the-first-100-largest-singular-values-of-the-term-document-matrix-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Perform LSI by selecting the first 100 largest singular values of the term document matrix</a></span></li><li><span><a href=\"#Transform-the-given-query\" data-toc-modified-id=\"Transform-the-given-query-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Transform the given query</a></span><ul class=\"toc-item\"><li><span><a href=\"#Treat-the-query-as-another-document\" data-toc-modified-id=\"Treat-the-query-as-another-document-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Treat the query as another document</a></span></li><li><span><a href=\"#Compute-the-query-vector-from-its-document-vector\" data-toc-modified-id=\"Compute-the-query-vector-from-its-document-vector-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Compute the query vector from its document vector</a></span></li></ul></li><li><span><a href=\"#Retrieve-top-10-relevant-documents\" data-toc-modified-id=\"Retrieve-top-10-relevant-documents-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Retrieve top-10 relevant documents</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fill-in-the-correct-parameters-in-the-following-function\" data-toc-modified-id=\"Fill-in-the-correct-parameters-in-the-following-function-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Fill in the correct parameters in the following function</a></span></li></ul></li><li><span><a href=\"#Compute-F1-score-at-10-between-the-oracle-and-your-result\" data-toc-modified-id=\"Compute-F1-score-at-10-between-the-oracle-and-your-result-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Compute F1-score at 10 between the oracle and your result</a></span></li><li><span><a href=\"#Compute-the-term-vectors-using-two-principal-concepts\" data-toc-modified-id=\"Compute-the-term-vectors-using-two-principal-concepts-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Compute the term vectors using two principal concepts</a></span></li><li><span><a href=\"#Explain-the-scatter-plot-of-the-term-vectors\" data-toc-modified-id=\"Explain-the-scatter-plot-of-the-term-vectors-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Explain the scatter plot of the term vectors</a></span></li><li><span><a href=\"#Submit-your-notebook\" data-toc-modified-id=\"Submit-your-notebook-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Submit your notebook</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "\n",
    "***Virtual Midterm Exam, Fall Semester 2020***\n",
    "\n",
    "The following materials are allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename your notebook\n",
    "Replace SciperNo with your **personal SCIPER Number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import math\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    documents = []\n",
    "    orig_docs = []\n",
    "    DIR = './'\n",
    "    tknzr = TweetTokenizer()\n",
    "    with open(\"epfldocs.txt\", encoding = \"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for text in content:\n",
    "        orig_docs.append(text)\n",
    "        # split into words\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        documents.append(' '.join(words))\n",
    "    return documents, orig_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, orig_docs = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(documents) == 1075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the vocabulary by selecting top-k frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary_frequency(corpus, vocab_len):\n",
    "    '''Select top-k (k = vocab_len) words in term of frequencies as vocabulary'''\n",
    "    \n",
    "    count = {} # dictionary that contains the frequency of each word count[word] = freq\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "    \n",
    "    sorted_count_by_freq = sorted(count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    vocabulary = [x[0] for x in sorted_count_by_freq[:vocab_len+1]]\n",
    "    \n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_freq = create_vocabulary_frequency(documents, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the term document matrix\n",
    "In this question, you need to construct the term document matrix given the vocabulary and the set of documents.\n",
    "The value of a cell (i,j) is the term frequency of the term i in document j.\n",
    "This is **different** from the definition from the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_term_document_matrix(vocabulary, documents):\n",
    "    matrix = np.zeros((len(vocabulary), len(documents)))\n",
    "    for j, document in enumerate(documents):\n",
    "        counter = Counter(document.split())\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix_freq = construct_term_document_matrix(vocab_freq, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform LSI by selecting the first 100 largest singular values of the term document matrix  \n",
    "Hint 1: np.linalg.svd(M, full_matrices=False) performs SVD on the matrix $\\mathbf{M}$ and returns $\\mathbf{K}, \\mathbf{S}, \\mathbf{D}^T$\n",
    "\n",
    " -  $\\mathbf{K}, \\mathbf{D}^T$ are matrices with orthonormal columns\n",
    " -  $\\mathbf{S}$ is a **vector** of singular values in a **descending** order\n",
    " \n",
    "Hint 2: np.diag(V) converts a vector to a diagonal matrix\n",
    "\n",
    "Hint 3: To select \n",
    " - The first k rows of a matrix A, use A[0:k, :]\n",
    " - The first k columns of a matrix A, use A[:, 0:k]\n",
    " - The submatrix from first k rows and k columns of a matrix A, use A[0:k, 0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a term document matrix and the number of singular values that will be selected\n",
    "# Output: K_s, S_s, Dt_s are similar to the defintion in the lecture\n",
    "def truncated_svd(term_doc_matrix, num_val):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return K_s, S_s, Dt_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_s, S_s, Dt_s = truncated_svd(term_doc_matrix_freq, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the given query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, you need to construct a vector representation for the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['epfl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat the query as another document \n",
    "\n",
    "Hint: vocabulary.index(word) returns the index of the word if the word is in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_document_vector(query, vocabulary):\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in query:\n",
    "        try:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "        except:\n",
    "            # if query word is not in vocabulary, ignore it\n",
    "            pass\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the query vector from its document vector\n",
    "\n",
    "Hint: \n",
    " -  To compute inverse of a matrix M, use np.linalg.inv(M)\n",
    " -  To compute the dot product of A, B, use np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query_vector(query, vocabulary, K_s, S_s, Dt_s):\n",
    "    q = query_to_document_vector(query, vocabulary)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return q_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector_freq = construct_query_vector(query, vocab_freq, K_s, S_s, Dt_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top-10 relevant documents\n",
    "In this question, you need to retrieve the top-10 documents that are relevant to the query using cosine similarity. You are given a function to compute the cosine simimlarity and a function that return the top-k documents given the query and document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_vector, top_k, doc_vecs):\n",
    "    scores = [[cosine_similarity(query_vector, doc_vecs[:,d]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    retrieved = []\n",
    "    for i in range(top_k):\n",
    "        doc_ids.append(scores[i][1])\n",
    "        retrieved.append(orig_docs[scores[i][1]])\n",
    "    return doc_ids, retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the correct parameters in the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_ids_freq, retrieved_docs_freq = retrieve_documents(# YOUR PARAMETERS HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "In this question, we consider the scikit reference code as an “oracle” that supposedly gives the correct result. You need to compare your retrieval results with this oracle using the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval oracle \n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), vocabulary=vocab_freq, min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(documents)\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.3):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1), \n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_ids are the document ids retrieved by the oracle\n",
    "gt_ids = search_vec_sklearn(\" \".join(query), features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute F1-score at 10 between the oracle and your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(predicted, oracle, k):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(predicted, oracle, k):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(predicted, oracle, k):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score(retrieved_ids_freq, gt_ids, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the term vectors using two principal concepts\n",
    "Hint: you can reuse a method from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_vecs_freq is a matrix of size (num_terms, 2)\n",
    "term_vecs_freq = # YOUR CODE HERE  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the scatter plot of the term vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(term_vecs_freq[:, 0], term_vecs_freq[:, 1])\n",
    "for i, t in enumerate(vocab_freq):\n",
    "    plt.annotate(t, (term_vecs_freq[i, 0], term_vecs_freq[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Do you see any outliers? What is a possible explanation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Link: https://moodle.epfl.ch/mod/quiz/view.php?id=1016203\n",
    "* Password: on the virtual blackboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "400px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
